\section*{Primer Parcial}
\subsection*{Práctica 1: Repaso álgebra lineal}
\begin{enumerate}
    \item $v^tuu^tv = (u^tv)^2$
    \item $AB \neq BA$
    \item $C(A+B) = CA + CB$
    \item $(AB)_{ij} = fila_i(A)*col_j(B)$
    \item $Ae_{i} = col_i(A)$
    \item $e_i^tA = fila_i(A)$
    \item $e_i^tAe_i = a_{ii}$
    \item Producto de matrices triangulares (sup o inf) es triangular (sup o inf)
    \item $dim(Im(A)) = rango(A)$ (cantidad de columnas linealmente independientes)
    \item Teorema de la dimensión: $A \in \mathbb{R}^{mxn}$, $dim(Nu(A)) + dim(Im(A)) = n$
    \item Matriz estrictamente diagonal dominante: $|a_{ii}| > \sum_{j=i}{}|a_{ij}|$
    \item Matriz inversa
    \begin{itemize}
    \item A inversible es equivalente a:
        \begin{itemize}
        \item $rango(A) = n$ (todas sus columnas son li)
        \item $det(A)\neq0$
        \item $Nu(A) = \{0\}$
        \item $Ax=b$ tiene única solución
        \item $A^tA$ es inversible
        \end{itemize}
    \item $AA^{-1} = A^{-1}A = I$
    \item $(AB)^{-1} = B^{-1}A^{-1}$
    \item $(A^t)^{-1} = (A^{-1})^t$
    \item $(kA)^{-1} = k^{-1} A^{-1}$, $k\in\mathbb{R}$
    \item La inversa de una matriz triangular superior es triangular inferior, y viceversa
    \end{itemize}
    \item Matriz traspuesta
    \begin{itemize}
        \item $(A+B)^t = A^t + B^t$
        \item $(AB)^t = B^tA^t$
    \end{itemize}
    \item $(A^t)^{-1} = (A^{-1})^t$
    \item Traza
    \begin{itemize}
        \item $tr(A) = \sum_{i=1}^{n}a_{ii}$ 
    \item $tr(AB) = tr(BA)$
    \item $tr(A+B) = tr(A)+tr(B)$
    \end{itemize}
    \item Determinante
    \begin{itemize}
        \item $det(AB) = det(A)*det(B)$
        \item $det(I) = 1$
        \item $det(A^{-1}) = (det(A))^{-1} \iff A$ es inversible
        \item $det(A) = \prod_{i=1}^{n}a_{ii} \iff A$ es triangular 
        \item $det(kA) = k^ndet(A)$
        \item $A \in \mathbb{R}^{2x2} \Rightarrow A^{-1} = \frac{1}{det(A)} \begin{pmatrix}
                        d & -b\\
                        -c & a
                        \end{pmatrix}$
    \end{itemize}
\end{enumerate}

\subsection*{Práctica 2: Eliminación Gaussiana y Normas}
\begin{enumerate}
    \item $\kappa_2(A) = ||A||_2 ||A^{-1}||_2$
    \item Normas vectoriales
    \begin{itemize}
        \item \textbf{Cauchy} $|z^tx|^2 \leq ||z||_2^2 ||x||_2^2$
         \item \textbf{Desigualdad triangular} $||x+y|| \leq ||x||+||y||$
        \item $||x||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}$
        \item $||x||_1 = \sum_{i=1}^{n} |x_i|$
        \item $||x||_{\infty}  = \max_{i=1 \dots n} x_i$
        \item $||x||_2^2 = x^tx$
        \item $||x||_{\infty} \leq ||x||_1$
        \item $||x||_1 \leq n ||x||_{\infty}$
        \item $||x||_{\infty} \leq ||x||_2$
    \end{itemize}
    \item Normas Matriciales
    \begin{itemize}
         \item $||A||_1 = \max_{1\leq j\leq n} \sum_{i=1}^{n} |a_{ij}|$ (máxima suma de cada columna)
          \item $||A||_{\infty} = \max_{1\leq i\leq n} \sum_{j=1}^{n} |a_{ij}|$ (máxima suma de cada fila)
         \item $||A||_2 = \max_{||x||_2=1} ||Ax||_2$
         \item $||A||_F = \sqrt{\sum_{i=1}^{n} \sum_{j=1}^{n} a_{ij}^2}$
        \item $||I|| = 1$
        \item $||Ax|| \leq ||A||*||x||$
        \item $||AB|| \leq ||A||*||B|| \iff$ A,B son matrices cuadradas
        \item $||A||_M \leq ||A||_2 \leq n ||A||_M$
    \end{itemize}
\end{enumerate}

\subsection*{Práctica 3: SDP y factorización de Cholesky}
\begin{enumerate}
    \item Matriz simétrica: $A=A^t$
    \item Matriz antisimétrica: $A^t=-A$
    \item $A+A^t$ es una matriz simétrica
    \item $A-A^t$ es una matriz antisimétrica
    \item Toda matriz puede escribirse como la suma entre una matriz simétrica y una antisimétrica
    \item Definida positiva $\iff x^tAx>0 \  \forall x \in \mathbb{R}^n x\neq0$
    \item Si A no es inversible, $AA^t$ es simétrica semi-definida positiva, es decir que $x^tAA^tx \geq 0 \forall x $
    \item Propiedades matrices SDP:
    \begin{itemize}
        \item Son inversibles
        \item $a_{ii} > 0$
        \item Tienen factorización LU
    \end{itemize}
    \item $A$ $sdp \iff B^tAB$ $sdp$ con $B$ inversible
    \item Si $A$ es $sdp$, el elemento de módulo máximo de A está en la diagonal. 
    \item Si $A$ es $sdp \Rightarrow |x^tAy| \leq \sqrt{x^tAx}\sqrt{y^tAy}$ 
    \item Si $A$ es $sdp \Rightarrow |a_{ij}|\leq a_{ii}a_{jj}$
    \item Factorización de Cholesky
    \begin{itemize}
        \item $A = LU = LDL^t = L\sqrt{D}\sqrt{D}L^t = \hat{L}\hat{L^t}$ donde $\hat{l}_{ii} = l_{ii}\sqrt{d_{ii}} = \sqrt{u_{ii}}$
        \item A tiene factorización de Cholesky $\iff$ A es $sdp$
    \end{itemize}
\end{enumerate}

\subsection*{Práctica 4: Matrices ortogonales y factorización QR}
\begin{enumerate}
    \item $u \perp v \iff u^tv=0$
    \item $Q \in \mathbb{R}^{nxn}$ ortogonal $\iff QQ^t=Q^tQ=I \land Q^t=Q^{-1}$
    \item $||Q||_2 = 1$
    \item $\kappa_2(Q) = 1$
    \item $||Qx||_2=||x||_2$
    \item Producto de matrices ortogonales es ortogonal
    \item Sus columnas son ortogonales entre sí y tienen norma 2 igual a 1, entonces forman un conjunto ortonormal
    \item $det(Q)= |1|$
    \item $Ax=b \Rightarrow Rx=Q^tb$
    \item Si $Q$ es ortogonal y triangular, entonces $Q$ es diagonal y además $col_i(Q)=\pm e_i$
    \item Matrices de rotación (Givens)
    \item Matrices de reflexión (Householder)
\end{enumerate}